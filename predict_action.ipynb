{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66842219",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eac98398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get real annotations\n",
    "# get start frames of clips\n",
    "# fine most common label for each clip\n",
    "# new dataset yay\n",
    "# fill into mask annotation and get loss???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ba45df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train\n",
    "train_file = '..\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_train.json'\n",
    "with open(train_file, 'r') as file:\n",
    "    train_data = json.load(file)['annotator-id_0']\n",
    "# load test\n",
    "test_file = '..\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_test.json'\n",
    "with open(test_file, 'r') as file:\n",
    "    test_data = json.load(file)['annotator-id_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28dc038d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_mask_annotations(data):\n",
    "    real_annotations = []\n",
    "    mask_annotations = []\n",
    "    for video in data:\n",
    "        real_annotations.append(np.array(data[video]['annotations']))\n",
    "        arr = np.array(data[video]['annotations'])\n",
    "        arr[arr < 2.5] = 0\n",
    "        arr[arr > 2.5] = 1\n",
    "        mask_annotations.append(arr)\n",
    "    return real_annotations, mask_annotations\n",
    "# annotations reduced to 1 and 0\n",
    "real_annotations, mask_annotations = real_mask_annotations(train_data)\n",
    "test_real_annotations, test_mask_annotations = real_mask_annotations(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4610d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_frames(data):\n",
    "    train_data = data\n",
    "    vid_start_frames = []\n",
    "    curr_frame = 0\n",
    "    for video_name in train_data.keys():\n",
    "        vid_start_frames.append(curr_frame)\n",
    "        vid_length = len(train_data[video_name]['annotations'])\n",
    "        curr_frame += vid_length\n",
    "    return vid_start_frames\n",
    "# what frame does a video start at\n",
    "vid_start_frames = start_frames(train_data)\n",
    "test_vid_start_frames = start_frames(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1927811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what frame of a video is an action at\n",
    "def action_frame_to_video_frame(actions_frame, vid_start_frames):\n",
    "    for i in range(len(vid_start_frames)-1):\n",
    "        if actions_frame >= vid_start_frames[i] and actions_frame < vid_start_frames[i+1]:\n",
    "            vid = i\n",
    "            frame_in = (actions_frame - vid_start_frames[i])\n",
    "            return vid, frame_in\n",
    "    vid = len(vid_start_frames)-1\n",
    "    frame_in = (actions_frame - vid_start_frames[-1])\n",
    "    return vid, frame_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf94b59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(file_path, real_annotations, vid_start_frames):\n",
    "    train_preds = np.load(file_path)\n",
    "    total = 0\n",
    "    actions_frames = []\n",
    "    for i in range(len(train_preds)-1):\n",
    "        if train_preds[i] == 1 and train_preds[i+1] == 0:\n",
    "            if np.unique(train_preds[i+1:i+300], return_counts=True)[1][0]/300 > 0.5:\n",
    "                total += 1\n",
    "                actions_frames.append(i+1)\n",
    "\n",
    "    actual_labels = []\n",
    "    for i in range(len(actions_frames)):\n",
    "        vid_start_frame = actions_frames[i]\n",
    "        vid, frame_in = action_frame_to_video_frame(vid_start_frame, vid_start_frames)\n",
    "        if i == len(actions_frames) - 1:\n",
    "            frame_size = 300\n",
    "        else:\n",
    "            frame_size = actions_frames[i+1] - vid_start_frame\n",
    "        if frame_size >= 300:\n",
    "            frame_size = 300\n",
    "        a = np.argmax(np.bincount(real_annotations[vid][frame_in:frame_in+frame_size])[:3])\n",
    "        # b = np.unique(real_annotations[vid][frame_in:frame_in+frame_size], return_counts=True)\n",
    "        actual_labels.append(a)\n",
    "        # value_pieces = real_annotations[vid][frame_in:frame_in+300]\n",
    "    return actual_labels, actions_frames\n",
    "    \n",
    "actual_labels, actual_actions_frames = get_labels('real_train_pred.npy', real_annotations, vid_start_frames)\n",
    "test_actual_labels, test_actions_frames = get_labels('test_files\\\\real_test_pred.npy', test_real_annotations, test_vid_start_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f0cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a011f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_embeddings = torch.load('..\\\\train_task1_embeddings.pt', map_location=torch.device('cpu'))\n",
    "test_video_embeddings = torch.load('..\\\\test_task1_embeddings.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c65580ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_video_embeddings = torch.load('..\\\\train_task2_embeddings.pt', map_location=torch.device('cpu'))\n",
    "t2_test_video_embeddings = torch.load('..\\\\test_task2_embeddings.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d6230d",
   "metadata": {},
   "source": [
    "LETS JUST DO KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f4997ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 2, 0, 2, 1, 2, 2, 2,\n",
       "       2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2,\n",
       "       1, 1, 1, 2, 1, 1, 0, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1,\n",
       "       1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2,\n",
       "       2, 2, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2,\n",
       "       2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 2, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_actual_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338176f",
   "metadata": {},
   "source": [
    "actual_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1329bcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 1536) (31, 1536)\n",
      "(855, 1536)\n"
     ]
    }
   ],
   "source": [
    "t2_labels = [-1 for i in range(31)]\n",
    "total_labels = actual_labels + t2_labels\n",
    "a = np.array(video_embeddings).reshape(824,1536)\n",
    "b = np.array(t2_video_embeddings).reshape(31,1536)\n",
    "print(a.shape, b.shape)\n",
    "total_x = np.concatenate((a,b))\n",
    "print(total_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9e31fbef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KNeighborsClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\">?<span>Documentation for KNeighborsClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_neighbors',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_neighbors&nbsp;</td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('weights',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">weights&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;uniform&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('algorithm',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">algorithm&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;auto&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('leaf_size',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">leaf_size&nbsp;</td>\n",
       "            <td class=\"value\">30</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('p',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">p&nbsp;</td>\n",
       "            <td class=\"value\">2</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;minkowski&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('metric_params',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">metric_params&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">n_jobs&nbsp;</td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "# neigh.fit(np.array(video_embeddings).reshape(824,1536), actual_labels)\n",
    "neigh.fit(total_x, total_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41f966a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i in range(len(test_video_embeddings)):\n",
    "    video = test_video_embeddings[i]\n",
    "    pred_val = neigh.predict(video)\n",
    "    predictions.append(pred_val)\n",
    "predictions = np.array(predictions)\n",
    "test_labels = np.array(test_actual_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e54b2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(t2_test_video_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9e2dcb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR T2\n",
    "predictions = []\n",
    "for i in range(len(t2_test_video_embeddings)):\n",
    "    video = t2_test_video_embeddings[i]\n",
    "    pred_val = neigh.predict(video)\n",
    "    predictions.append(pred_val)\n",
    "predictions = np.array(predictions)\n",
    "t2_test_labels = [-1 for i in range(27)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ec4f0185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "f1_scores = sklearn.metrics.f1_score(t2_test_labels, predictions, average='macro')\n",
    "rec_scores = sklearn.metrics.precision_score(t2_test_labels, predictions, average='macro')\n",
    "prec_scores = sklearn.metrics.recall_score(t2_test_labels, predictions, average='macro')\n",
    "print(f1_scores, rec_scores, prec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fccbd60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3287568924097426 0.37327415869095404 0.34371036508903297\n"
     ]
    }
   ],
   "source": [
    "f1_scores = sklearn.metrics.f1_score(test_labels, predictions, average='macro')\n",
    "rec_scores = sklearn.metrics.precision_score(test_labels, predictions, average='macro')\n",
    "prec_scores = sklearn.metrics.recall_score(test_labels, predictions, average='macro')\n",
    "print(f1_scores, rec_scores, prec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80bfe100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4652777777777778"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accur = sklearn.metrics.accuracy_score(test_labels, predictions)\n",
    "accur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "986808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_action_predictions = np.load('test_files\\\\real_test_pred.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "6504f8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all 1 into 3 test_action_predictions\n",
    "test_action_predictions[test_action_predictions==1] = 3\n",
    "for i in range(len(test_actions_frames)):\n",
    "    # fill in test_action_predictions\n",
    "    start_fill = test_actions_frames[i]\n",
    "    fill_with = predictions[i]\n",
    "    test_action_predictions[start_fill + 1:][test_action_predictions[start_fill + 1:]!=3] = fill_with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ab95477a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([ 21301,  82416,  10678, 147712]))"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_action_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7702aeb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7273975895340452 0.4556433034793878 0.4940225088151319 0.4631689504164316\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "official = np.array(list(itertools.chain.from_iterable(test_real_annotations)))\n",
    "ours = test_action_predictions\n",
    "accur = sklearn.metrics.accuracy_score(official, ours)\n",
    "f1_scores = sklearn.metrics.f1_score(official, ours, average='macro')\n",
    "rec_scores = sklearn.metrics.precision_score(official, ours, average='macro')\n",
    "prec_scores = sklearn.metrics.recall_score(official, ours, average='macro')\n",
    "print(accur, f1_scores, rec_scores, prec_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06912b11",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d79a40fb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72e93a38",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e926b869",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "95a9070c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch Tensors\n",
    "X_tensor = torch.cat(video_embeddings, dim=0)\n",
    "y_tensor = torch.tensor(to_categorical(torch.reshape(torch.tensor(actual_labels), (len(actual_labels), 1))))\n",
    "X_test = torch.cat(test_video_embeddings, dim=0)\n",
    "y_test = torch.tensor(to_categorical(torch.reshape(torch.tensor(test_actual_labels), (len(test_actual_labels), 1))))\n",
    "\n",
    "# 2. Define the Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# 3. Instantiate the Model, Loss Function, and Optimizer\n",
    "input_size = video_embeddings[0].shape[1]\n",
    "hidden_size = 10\n",
    "output_size = 3\n",
    "learning_rate = 0.00000001\n",
    "num_epochs = 200\n",
    "batch_size = 1\n",
    "batch_no = len(actual_labels) // batch_size\n",
    "\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "61a1f300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Loss: 1.0714\n",
      "train 101\n",
      "test 76\n",
      "Epoch [2/200], Loss: 1.0729\n",
      "train 101\n",
      "test 76\n",
      "Epoch [3/200], Loss: 1.0744\n",
      "train 101\n",
      "test 76\n",
      "Epoch [4/200], Loss: 1.0760\n",
      "train 101\n",
      "test 76\n",
      "Epoch [5/200], Loss: 1.0775\n",
      "train 101\n",
      "test 76\n",
      "Epoch [6/200], Loss: 1.0790\n",
      "train 101\n",
      "test 76\n",
      "Epoch [7/200], Loss: 1.0805\n",
      "train 101\n",
      "test 76\n",
      "Epoch [8/200], Loss: 1.0820\n",
      "train 101\n",
      "test 76\n",
      "Epoch [9/200], Loss: 1.0835\n",
      "train 101\n",
      "test 76\n",
      "Epoch [10/200], Loss: 1.0850\n",
      "train 101\n",
      "test 76\n",
      "Epoch [11/200], Loss: 1.0866\n",
      "train 101\n",
      "test 76\n",
      "Epoch [12/200], Loss: 1.0881\n",
      "train 101\n",
      "test 76\n",
      "Epoch [13/200], Loss: 1.0896\n",
      "train 101\n",
      "test 76\n",
      "Epoch [14/200], Loss: 1.0911\n",
      "train 101\n",
      "test 76\n",
      "Epoch [15/200], Loss: 1.0926\n",
      "train 101\n",
      "test 76\n",
      "Epoch [16/200], Loss: 1.0941\n",
      "train 101\n",
      "test 76\n",
      "Epoch [17/200], Loss: 1.0956\n",
      "train 101\n",
      "test 76\n",
      "Epoch [18/200], Loss: 1.0971\n",
      "train 101\n",
      "test 76\n",
      "Epoch [19/200], Loss: 1.0986\n",
      "train 101\n",
      "test 76\n",
      "Epoch [20/200], Loss: 1.1001\n",
      "train 101\n",
      "test 76\n",
      "Epoch [21/200], Loss: 1.1016\n",
      "train 101\n",
      "test 76\n",
      "Epoch [22/200], Loss: 1.1031\n",
      "train 101\n",
      "test 76\n",
      "Epoch [23/200], Loss: 1.1046\n",
      "train 101\n",
      "test 76\n",
      "Epoch [24/200], Loss: 1.1061\n",
      "train 101\n",
      "test 76\n",
      "Epoch [25/200], Loss: 1.1076\n",
      "train 101\n",
      "test 76\n",
      "Epoch [26/200], Loss: 1.1090\n",
      "train 101\n",
      "test 76\n",
      "Epoch [27/200], Loss: 1.1105\n",
      "train 101\n",
      "test 76\n",
      "Epoch [28/200], Loss: 1.1120\n",
      "train 101\n",
      "test 76\n",
      "Epoch [29/200], Loss: 1.1134\n",
      "train 101\n",
      "test 76\n",
      "Epoch [30/200], Loss: 1.1149\n",
      "train 101\n",
      "test 76\n",
      "Epoch [31/200], Loss: 1.1164\n",
      "train 101\n",
      "test 76\n",
      "Epoch [32/200], Loss: 1.1178\n",
      "train 101\n",
      "test 76\n",
      "Epoch [33/200], Loss: 1.1193\n",
      "train 101\n",
      "test 76\n",
      "Epoch [34/200], Loss: 1.1207\n",
      "train 101\n",
      "test 76\n",
      "Epoch [35/200], Loss: 1.1222\n",
      "train 101\n",
      "test 76\n",
      "Epoch [36/200], Loss: 1.1236\n",
      "train 101\n",
      "test 76\n",
      "Epoch [37/200], Loss: 1.1251\n",
      "train 101\n",
      "test 76\n",
      "Epoch [38/200], Loss: 1.1265\n",
      "train 101\n",
      "test 76\n",
      "Epoch [39/200], Loss: 1.1279\n",
      "train 101\n",
      "test 76\n",
      "Epoch [40/200], Loss: 1.1294\n",
      "train 101\n",
      "test 76\n",
      "Epoch [41/200], Loss: 1.1308\n",
      "train 101\n",
      "test 76\n",
      "Epoch [42/200], Loss: 1.1322\n",
      "train 101\n",
      "test 76\n",
      "Epoch [43/200], Loss: 1.1336\n",
      "train 101\n",
      "test 76\n",
      "Epoch [44/200], Loss: 1.1350\n",
      "train 101\n",
      "test 76\n",
      "Epoch [45/200], Loss: 1.1364\n",
      "train 101\n",
      "test 76\n",
      "Epoch [46/200], Loss: 1.1378\n",
      "train 101\n",
      "test 76\n",
      "Epoch [47/200], Loss: 1.1392\n",
      "train 101\n",
      "test 76\n",
      "Epoch [48/200], Loss: 1.1406\n",
      "train 101\n",
      "test 76\n",
      "Epoch [49/200], Loss: 1.1420\n",
      "train 101\n",
      "test 76\n",
      "Epoch [50/200], Loss: 1.1434\n",
      "train 101\n",
      "test 76\n",
      "Epoch [51/200], Loss: 1.1448\n",
      "train 101\n",
      "test 76\n",
      "Epoch [52/200], Loss: 1.1462\n",
      "train 101\n",
      "test 76\n",
      "Epoch [53/200], Loss: 1.1475\n",
      "train 101\n",
      "test 76\n",
      "Epoch [54/200], Loss: 1.1489\n",
      "train 101\n",
      "test 76\n",
      "Epoch [55/200], Loss: 1.1503\n",
      "train 101\n",
      "test 76\n",
      "Epoch [56/200], Loss: 1.1517\n",
      "train 101\n",
      "test 76\n",
      "Epoch [57/200], Loss: 1.1530\n",
      "train 101\n",
      "test 76\n",
      "Epoch [58/200], Loss: 1.1544\n",
      "train 101\n",
      "test 76\n",
      "Epoch [59/200], Loss: 1.1557\n",
      "train 101\n",
      "test 76\n",
      "Epoch [60/200], Loss: 1.1570\n",
      "train 101\n",
      "test 76\n",
      "Epoch [61/200], Loss: 1.1584\n",
      "train 101\n",
      "test 76\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[119]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     23\u001b[39m     loss = criterion(ypred_var, y_var)\n\u001b[32m     24\u001b[39m     loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (epoch + \u001b[32m1\u001b[39m) % \u001b[32m1\u001b[39m == \u001b[32m0\u001b[39m:\n\u001b[32m     29\u001b[39m     \u001b[38;5;66;03m# other_crit = nn.CrossEntropyLoss()\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\torch\\optim\\adam.py:535\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    533\u001b[39m         denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m         denom = \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     param.addcdiv_(exp_avg, denom, value=-step_size)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # x_train, y_train = shuffle(x_train, y_train)\n",
    "    x_train, y_train = X_tensor, y_tensor\n",
    "    # Mini batch learning\n",
    "    for i in range(batch_no):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "\n",
    "        x_var = x_train[start:end]\n",
    "        y_var = y_train[start:end]\n",
    "        # print(y_var)\n",
    "\n",
    "        # Restart the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Run a training step: Pass the training data to\n",
    "        # the neural network layers\n",
    "        ypred_var = model(x_var)\n",
    "        # print(ypred_var)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss = criterion(ypred_var, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        # other_crit = nn.CrossEntropyLoss()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}') #, Test Loss: {other_crit(model(X_test), y_test)}')\n",
    "        print('train',np.sum(0==(np.argmax(model(X_tensor).detach().numpy(), axis=1) - np.argmax(y_tensor.detach().numpy(),axis=1))))\n",
    "        print('test',np.sum(0==(np.argmax(model(X_test).detach().numpy(), axis=1) - np.argmax(y_test.detach().numpy(),axis=1))))\n",
    "    # # Forward pass\n",
    "    # outputs = model(X_tensor)\n",
    "    # loss = criterion(outputs, y_tensor)\n",
    "\n",
    "    # # Backward and optimize\n",
    "    # optimizer.zero_grad()\n",
    "    # loss.backward()\n",
    "    # optimizer.step()\n",
    "\n",
    "    # if (epoch + 1) % 100 == 0:\n",
    "    #     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# # 5. Evaluation\n",
    "# with torch.no_grad():\n",
    "#     predicted = (torch.sigmoid(model(X_tensor)) > 0.5).float()\n",
    "#     accuracy = (predicted == y_tensor).sum().item() / y_tensor.size(0)\n",
    "#     print(f'Accuracy of the model on the synthetic data: {accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f75406",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = torch.load('..\\\\test_task1_embeddings.pt', map_location=torch.device('cpu'))\n",
    "X_tensor = torch.cat(test_embeddings, dim=0)\n",
    "y_tensor = torch.tensor(to_categorical(torch.reshape(torch.tensor(actual_labels), (len(actual_labels), 1))))\n",
    "test_loss = criterion(model(x_var), y_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc853d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.argmax(model(X_tensor).detach().numpy(), axis=1)\n",
    "b = np.argmax(y_tensor, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bf213",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_36096\\1689630220.py:1: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  np.equal(a,b)\n",
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_36096\\1689630220.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  np.unique(np.equal(a,b), return_counts=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([249, 575]))"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.equal(a,b)\n",
    "np.unique(np.equal(a,b), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67305ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = torch.load('..\\\\test_task1_embeddings.pt', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f201ce7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e3bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = sklearn.metrics.f1_score(labels, predictions, average=None)\n",
    "rec_scores = sklearn.metrics.precision_score(labels, predictions, average=None)\n",
    "prec_scores = sklearn.metrics.recall_score(labels, predictions, average=None)\n",
    "\n",
    "# Average precsion - all labels not equal to correct label are mistakes\n",
    "ap_scores = []\n",
    "for single_label in sorted(np.unique(labels)):\n",
    "    labels_l = labels == single_label\n",
    "    probabilites_l = probabilites[:, single_label]\n",
    "    ap_score_l = sklearn.metrics.average_precision_score(\n",
    "        labels_l, probabilites_l, average=\"micro\"\n",
    "    )\n",
    "    ap_scores.append(ap_score_l)\n",
    "\n",
    "classes = sorted(self.class_to_number, key=self.class_to_number.get)\n",
    "metrics = pd.DataFrame(\n",
    "    {\n",
    "        \"Class\": classes,\n",
    "        \"F1\": f1_scores,\n",
    "        \"Precision\": prec_scores,\n",
    "        \"Recall\": rec_scores,\n",
    "        \"Average Precision\": ap_scores,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
