{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2740fccd",
   "metadata": {},
   "source": [
    "# Train Final Action Prediction Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16c320a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee7fa56",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m train_file = \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtask1_classic_classification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtask1_classic_classification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mcalms21_task1_train.json\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[32m      3\u001b[39m     train_data = json.load(file)\n\u001b[32m      4\u001b[39m test_file = \u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtask1_classic_classification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mtask1_classic_classification\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mcalms21_task1_test.json\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\cmouse\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '.\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_train.json'"
     ]
    }
   ],
   "source": [
    "train_file = '.\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_train.json'\n",
    "with open(train_file, 'r') as file:\n",
    "    train_data = json.load(file)\n",
    "test_file = '.\\\\task1_classic_classification\\\\task1_classic_classification\\\\calms21_task1_test.json'\n",
    "with open(test_file, 'r') as file:\n",
    "    test_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad841f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(data):\n",
    "    new_data = []\n",
    "    for vid in data:\n",
    "        # split into 150 frame pieces\n",
    "        if vid.shape[0] > 160:\n",
    "            section_size = 10\n",
    "            num_splits = vid.shape[0] // section_size\n",
    "            elements_to_keep = section_size * num_splits\n",
    "            truncated_vid = vid[:elements_to_keep]\n",
    "            new_data += np.split(truncated_vid, num_splits)\n",
    "    return np.array(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99a07672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 50% of a window has an action then count it as worthy\n",
    "# {'attack': 0, 'investigation': 1, 'mount': 2, 'other': 3}\n",
    "def reduce_labels(data):\n",
    "    reduced_data = []\n",
    "    action_percent = 0.5\n",
    "    for clip in data:\n",
    "        if (clip < 3).sum() > clip.size*action_percent:\n",
    "            reduced_data.append(1)\n",
    "        else:\n",
    "            reduced_data.append(0)\n",
    "    return np.array(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53fc79d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label 1 means there is an action\n",
    "train_x = chunk([np.array(video['keypoints']) for video in train_data['annotator-id_0'].values()])\n",
    "train_y = (chunk([np.array(video['annotations']) for video in train_data['annotator-id_0'].values()]))\n",
    "test_x = chunk([np.array(video['keypoints']) for video in test_data['annotator-id_0'].values()])\n",
    "test_y = (chunk([np.array(video['annotations']) for video in test_data['annotator-id_0'].values()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2366eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape(train_x.shape[0], -1)\n",
    "test_x = test_x.reshape(test_x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "12f27c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(0.02752626288507401),\n",
       " np.float64(0.2888877939176538),\n",
       " np.float64(0.05635926444212311),\n",
       " np.float64(0.6272266787551491)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_stats(data):\n",
    "    total = data.size\n",
    "    return [(data==i).sum()/total for i in range(4)]\n",
    "get_stats(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "baed8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        depth = 3\n",
    "        layers = [\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU()]\n",
    "        for i in range(depth):\n",
    "            layers.append(nn.Linear(hidden_size, hidden_size)),\n",
    "            layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_size, output_size))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4b771a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "print_every = 100\n",
    "input_size = 10*2*2*7\n",
    "hidden_size = 1000\n",
    "output_size = 1\n",
    "model = SimpleNN(input_size, hidden_size, output_size)\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "loss_fcn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6cb3656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_22452\\2581623885.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_x = torch.tensor(train_x, dtype=torch.float32)\n",
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_22452\\2581623885.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y, dtype=torch.float32)\n",
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_22452\\2581623885.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(test_x, dtype=torch.float32)\n",
      "C:\\Users\\audre\\AppData\\Local\\Temp\\ipykernel_22452\\2581623885.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y = torch.tensor(test_y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.tensor(train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1a240540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleNN(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=280, out_features=1000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=1000, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "34da84e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = model.forward(test_x)\n",
    "def accuracy(preds, real):\n",
    "    return ((preds > 0.5).int().flatten() == real).sum() / test_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a65d2c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:634: UserWarning: Using a target size (torch.Size([26203, 1])) that is different to the input size (torch.Size([26203])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, train_loss 7.6030e-01, test_loss 1.0232e+03\n",
      "accuracy tensor(0.4003)\n",
      "iter 100, train_loss 9.1046e-02, test_loss 1.0449e+01\n",
      "accuracy tensor(0.5170)\n",
      "iter 200, train_loss 1.9693e+00, test_loss 2.8038e+01\n",
      "accuracy tensor(0.4837)\n",
      "iter 300, train_loss 2.9931e+00, test_loss 3.5303e+01\n",
      "accuracy tensor(0.4002)\n",
      "iter 400, train_loss 1.5055e+00, test_loss 4.1165e+00\n",
      "accuracy tensor(0.4722)\n",
      "iter 500, train_loss 2.8877e-01, test_loss 6.6426e+00\n",
      "accuracy tensor(0.6063)\n",
      "iter 600, train_loss 3.3489e-03, test_loss 7.7160e+00\n",
      "accuracy tensor(0.5909)\n",
      "iter 700, train_loss 3.3115e-02, test_loss 8.3213e+00\n",
      "accuracy tensor(0.3927)\n",
      "iter 800, train_loss 3.8180e-02, test_loss 1.7467e+01\n",
      "accuracy tensor(0.3957)\n",
      "iter 900, train_loss 2.0368e-02, test_loss 1.3839e+01\n",
      "accuracy tensor(0.5973)\n",
      "iter 1000, train_loss 6.4135e-04, test_loss 2.1734e+00\n",
      "accuracy tensor(0.4914)\n",
      "iter 1100, train_loss 6.5341e-02, test_loss 2.0716e+00\n",
      "accuracy tensor(0.5997)\n",
      "iter 1200, train_loss 7.9724e-01, test_loss 6.2251e-01\n",
      "accuracy tensor(0.4449)\n",
      "iter 1300, train_loss 2.1158e-01, test_loss 6.3773e-01\n",
      "accuracy tensor(0.4238)\n",
      "iter 1400, train_loss 5.1643e-03, test_loss 3.1888e+00\n",
      "accuracy tensor(0.6039)\n",
      "iter 1500, train_loss 1.0175e-02, test_loss 2.7008e+00\n",
      "accuracy tensor(0.5291)\n",
      "iter 1600, train_loss 2.6203e-02, test_loss 9.0889e-01\n",
      "accuracy tensor(0.5946)\n",
      "iter 1700, train_loss 2.9284e-03, test_loss 6.4263e-01\n",
      "accuracy tensor(0.4737)\n",
      "iter 1800, train_loss 2.3227e-03, test_loss 4.3410e-01\n",
      "accuracy tensor(0.5394)\n",
      "iter 1900, train_loss 3.5385e-02, test_loss 1.9218e+00\n",
      "accuracy tensor(0.3871)\n",
      "iter 2000, train_loss 3.1621e-02, test_loss 3.4902e-01\n",
      "accuracy tensor(0.4823)\n",
      "iter 2100, train_loss 3.7245e-01, test_loss 4.0526e-01\n",
      "accuracy tensor(0.4255)\n",
      "iter 2200, train_loss 1.7628e-03, test_loss 7.0931e-01\n",
      "accuracy tensor(0.3542)\n",
      "iter 2300, train_loss 2.2805e-01, test_loss 7.7280e-01\n",
      "accuracy tensor(0.4708)\n",
      "iter 2400, train_loss 1.3275e-01, test_loss 7.3139e-01\n",
      "accuracy tensor(0.5467)\n",
      "iter 2500, train_loss 2.8209e-02, test_loss 7.0057e-01\n",
      "accuracy tensor(0.5156)\n",
      "iter 2600, train_loss 4.1291e-02, test_loss 5.2629e-01\n",
      "accuracy tensor(0.5403)\n",
      "iter 2700, train_loss 6.3659e-03, test_loss 4.6633e-01\n",
      "accuracy tensor(0.5575)\n",
      "iter 2800, train_loss 2.1783e+00, test_loss 7.7896e-01\n",
      "accuracy tensor(0.5109)\n",
      "iter 2900, train_loss 1.6128e-01, test_loss 4.8165e-01\n",
      "accuracy tensor(0.5541)\n",
      "iter 3000, train_loss 1.9741e-02, test_loss 5.0170e-01\n",
      "accuracy tensor(0.5730)\n",
      "iter 3100, train_loss 2.7598e-01, test_loss 5.0114e-01\n",
      "accuracy tensor(0.5827)\n",
      "iter 3200, train_loss 9.9295e-01, test_loss 8.2025e-01\n",
      "accuracy tensor(0.5940)\n",
      "iter 3300, train_loss 2.4144e-06, test_loss 6.3794e-01\n",
      "accuracy tensor(0.6301)\n",
      "iter 3400, train_loss 1.7531e-01, test_loss 4.4736e-01\n",
      "accuracy tensor(0.6313)\n",
      "iter 3500, train_loss 4.6370e-02, test_loss 4.6620e-01\n",
      "accuracy tensor(0.6257)\n",
      "iter 3600, train_loss 6.7602e-04, test_loss 4.6154e-01\n",
      "accuracy tensor(0.7219)\n",
      "iter 3700, train_loss 6.6316e-05, test_loss 4.5684e-01\n",
      "accuracy tensor(0.7010)\n",
      "iter 3800, train_loss 3.2075e-04, test_loss 4.3560e-01\n",
      "accuracy tensor(0.6684)\n",
      "iter 3900, train_loss 2.7795e-01, test_loss 3.1729e-01\n",
      "accuracy tensor(0.6838)\n",
      "iter 4000, train_loss 1.5505e-01, test_loss 7.4434e-01\n",
      "accuracy tensor(0.6899)\n",
      "iter 4100, train_loss 3.8670e-01, test_loss 3.0889e+00\n",
      "accuracy tensor(0.6324)\n",
      "iter 4200, train_loss 1.0070e+00, test_loss 1.7900e+00\n",
      "accuracy tensor(0.6050)\n",
      "iter 4300, train_loss 3.2261e-02, test_loss 8.7903e-01\n",
      "accuracy tensor(0.6583)\n",
      "iter 4400, train_loss 3.3095e-02, test_loss 7.9913e-01\n",
      "accuracy tensor(0.4104)\n",
      "iter 4500, train_loss 1.9969e-02, test_loss 4.5071e-01\n",
      "accuracy tensor(0.6648)\n",
      "iter 4600, train_loss 4.5088e-07, test_loss 8.2096e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 4700, train_loss 6.5485e-02, test_loss 3.1426e-01\n",
      "accuracy tensor(0.6266)\n",
      "iter 4800, train_loss 7.9243e-03, test_loss 3.5380e-01\n",
      "accuracy tensor(0.5829)\n",
      "iter 4900, train_loss 8.8546e-04, test_loss 4.8127e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 5000, train_loss 6.2110e-02, test_loss 1.2599e+00\n",
      "accuracy tensor(0.4771)\n",
      "iter 5100, train_loss 2.4997e-03, test_loss 5.8476e-01\n",
      "accuracy tensor(0.5805)\n",
      "iter 5200, train_loss 6.5674e-03, test_loss 6.8718e-01\n",
      "accuracy tensor(0.6211)\n",
      "iter 5300, train_loss 2.5503e-03, test_loss 6.1146e-01\n",
      "accuracy tensor(0.5991)\n",
      "iter 5400, train_loss 1.2425e-01, test_loss 3.2732e-01\n",
      "accuracy tensor(0.6039)\n",
      "iter 5500, train_loss 6.2712e-03, test_loss 3.6464e-01\n",
      "accuracy tensor(0.5586)\n",
      "iter 5600, train_loss 3.2703e-06, test_loss 4.3255e-01\n",
      "accuracy tensor(0.5989)\n",
      "iter 5700, train_loss 6.2929e-05, test_loss 6.0162e-01\n",
      "accuracy tensor(0.5892)\n",
      "iter 5800, train_loss 3.6934e-02, test_loss 7.4211e-01\n",
      "accuracy tensor(0.5995)\n",
      "iter 5900, train_loss 9.7955e-03, test_loss 3.7734e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 6000, train_loss 1.0098e-02, test_loss 4.1133e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 6100, train_loss 7.4218e-03, test_loss 5.2798e-01\n",
      "accuracy tensor(0.5996)\n",
      "iter 6200, train_loss 7.7066e-03, test_loss 3.1968e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 6300, train_loss 8.4928e-03, test_loss 6.5631e-01\n",
      "accuracy tensor(0.6621)\n",
      "iter 6400, train_loss 3.0714e-02, test_loss 4.1020e-01\n",
      "accuracy tensor(0.5118)\n",
      "iter 6500, train_loss 2.8686e-01, test_loss 2.6726e-01\n",
      "accuracy tensor(0.5603)\n",
      "iter 6600, train_loss 4.1837e-03, test_loss 4.9637e-01\n",
      "accuracy tensor(0.6099)\n",
      "iter 6700, train_loss 7.4905e-01, test_loss 2.7877e-01\n",
      "accuracy tensor(0.6381)\n",
      "iter 6800, train_loss 8.2719e-01, test_loss 3.3137e-01\n",
      "accuracy tensor(0.6342)\n",
      "iter 6900, train_loss 1.0550e+00, test_loss 5.1445e-01\n",
      "accuracy tensor(0.6442)\n",
      "iter 7000, train_loss 1.4691e-01, test_loss 1.2531e+00\n",
      "accuracy tensor(0.4525)\n",
      "iter 7100, train_loss 7.4639e-02, test_loss 2.8567e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 7200, train_loss 8.3885e-04, test_loss 5.4089e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 7300, train_loss 4.8831e-01, test_loss 2.7209e-01\n",
      "accuracy tensor(0.6424)\n",
      "iter 7400, train_loss 4.0849e-03, test_loss 5.7442e-01\n",
      "accuracy tensor(0.3830)\n",
      "iter 7500, train_loss 5.2747e-03, test_loss 4.7406e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 7600, train_loss 1.4720e-04, test_loss 3.2741e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 7700, train_loss 1.5683e-02, test_loss 3.2253e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 7800, train_loss 5.6897e-02, test_loss 4.3893e-01\n",
      "accuracy tensor(0.4785)\n",
      "iter 7900, train_loss 2.8255e-03, test_loss 3.5197e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 8000, train_loss 2.0411e-02, test_loss 3.5462e-01\n",
      "accuracy tensor(0.4888)\n",
      "iter 8100, train_loss 4.3066e-02, test_loss 5.8838e-01\n",
      "accuracy tensor(0.4959)\n",
      "iter 8200, train_loss 6.1799e-01, test_loss 2.6206e-01\n",
      "accuracy tensor(0.6070)\n",
      "iter 8300, train_loss 9.8004e-03, test_loss 3.4397e-01\n",
      "accuracy tensor(0.5136)\n",
      "iter 8400, train_loss 1.3097e-02, test_loss 7.4107e-01\n",
      "accuracy tensor(0.5281)\n",
      "iter 8500, train_loss 6.6529e-04, test_loss 4.4316e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 8600, train_loss 7.2227e-01, test_loss 3.1307e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 8700, train_loss 2.5727e-02, test_loss 2.9373e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 8800, train_loss 2.9391e-01, test_loss 2.8829e-01\n",
      "accuracy tensor(0.5875)\n",
      "iter 8900, train_loss 4.8526e-04, test_loss 6.7050e-01\n",
      "accuracy tensor(0.4286)\n",
      "iter 9000, train_loss 4.5781e-03, test_loss 4.9164e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 9100, train_loss 9.6031e-02, test_loss 3.0404e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 9200, train_loss 7.7152e-04, test_loss 6.0209e-01\n",
      "accuracy tensor(0.4316)\n",
      "iter 9300, train_loss 2.4411e-01, test_loss 2.5415e+00\n",
      "accuracy tensor(0.4285)\n",
      "iter 9400, train_loss 4.6313e-04, test_loss 3.9853e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 9500, train_loss 1.3279e-01, test_loss 2.1590e+00\n",
      "accuracy tensor(0.4103)\n",
      "iter 9600, train_loss 4.2169e-02, test_loss 2.8160e-01\n",
      "accuracy tensor(0.6007)\n",
      "iter 9700, train_loss 1.4288e-03, test_loss 4.4439e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 9800, train_loss 3.8417e-01, test_loss 2.4498e-01\n",
      "accuracy tensor(0.5791)\n",
      "iter 9900, train_loss 1.2008e-03, test_loss 4.5141e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10000, train_loss 3.9149e-03, test_loss 2.9746e-01\n",
      "accuracy tensor(0.6663)\n",
      "iter 10100, train_loss 1.4047e-02, test_loss 3.4673e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10200, train_loss 1.9108e-03, test_loss 3.3770e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10300, train_loss 2.4288e-01, test_loss 2.8132e-01\n",
      "accuracy tensor(0.6483)\n",
      "iter 10400, train_loss 1.0178e-02, test_loss 3.1555e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10500, train_loss 1.1406e-01, test_loss 5.1185e-01\n",
      "accuracy tensor(0.5157)\n",
      "iter 10600, train_loss 1.5591e-02, test_loss 2.9491e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10700, train_loss 1.0826e-02, test_loss 3.8507e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 10800, train_loss 5.9203e-04, test_loss 4.5884e-01\n",
      "accuracy tensor(0.4136)\n",
      "iter 10900, train_loss 5.3936e-02, test_loss 2.9936e-01\n",
      "accuracy tensor(0.4817)\n",
      "iter 11000, train_loss 4.2244e-01, test_loss 2.8320e-01\n",
      "accuracy tensor(0.6062)\n",
      "iter 11100, train_loss 1.2942e-04, test_loss 3.6668e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 11200, train_loss 2.4765e-03, test_loss 3.2312e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 11300, train_loss 3.7176e-02, test_loss 2.5392e-01\n",
      "accuracy tensor(0.5726)\n",
      "iter 11400, train_loss 3.8010e-03, test_loss 3.4734e-01\n",
      "accuracy tensor(0.5958)\n",
      "iter 11500, train_loss 7.3938e-01, test_loss 3.2379e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 11600, train_loss 1.9203e-03, test_loss 3.1225e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 11700, train_loss 5.7439e-02, test_loss 3.0271e-01\n",
      "accuracy tensor(0.5702)\n",
      "iter 11800, train_loss 1.4223e-06, test_loss 4.9900e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 11900, train_loss 5.7817e-01, test_loss 3.2582e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12000, train_loss 7.2204e-01, test_loss 3.3792e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12100, train_loss 6.5192e-01, test_loss 2.9479e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12200, train_loss 9.5304e-05, test_loss 3.0504e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12300, train_loss 6.0515e-07, test_loss 3.0033e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12400, train_loss 1.6588e-03, test_loss 5.0038e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12500, train_loss 1.9805e-05, test_loss 2.9917e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12600, train_loss 1.7273e-03, test_loss 6.7019e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12700, train_loss 6.1090e-01, test_loss 2.5822e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12800, train_loss 3.4736e-02, test_loss 2.6991e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 12900, train_loss 1.1746e-02, test_loss 4.3353e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13000, train_loss 7.2406e-06, test_loss 4.4130e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13100, train_loss 5.2782e-04, test_loss 4.2135e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13200, train_loss 1.3095e-02, test_loss 3.0349e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13300, train_loss 2.5431e-02, test_loss 2.7758e-01\n",
      "accuracy tensor(0.5995)\n",
      "iter 13400, train_loss 7.2246e-01, test_loss 2.7112e-01\n",
      "accuracy tensor(0.5987)\n",
      "iter 13500, train_loss 1.0798e-03, test_loss 3.6305e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13600, train_loss 1.1131e-04, test_loss 7.1561e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13700, train_loss 5.8120e-04, test_loss 4.6588e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13800, train_loss 2.4761e-02, test_loss 2.8993e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 13900, train_loss 7.3391e-01, test_loss 2.8526e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14000, train_loss 6.3922e-02, test_loss 2.8258e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14100, train_loss 5.4430e-01, test_loss 2.5287e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14200, train_loss 2.4280e-05, test_loss 3.4035e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14300, train_loss 1.1047e-04, test_loss 3.5537e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14400, train_loss 7.8075e-02, test_loss 4.2263e-01\n",
      "accuracy tensor(0.4971)\n",
      "iter 14500, train_loss 6.4533e-01, test_loss 2.8145e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14600, train_loss 1.2876e-01, test_loss 2.5054e-01\n",
      "accuracy tensor(0.5988)\n",
      "iter 14700, train_loss 5.6745e-03, test_loss 3.0345e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14800, train_loss 3.9653e-06, test_loss 3.0954e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 14900, train_loss 5.3356e-01, test_loss 2.6363e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15000, train_loss 5.4418e-01, test_loss 3.1075e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15100, train_loss 8.3835e-01, test_loss 2.9237e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15200, train_loss 4.5980e-01, test_loss 2.5006e-01\n",
      "accuracy tensor(0.5818)\n",
      "iter 15300, train_loss 5.9149e-05, test_loss 6.4047e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15400, train_loss 1.7118e-03, test_loss 3.8697e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15500, train_loss 5.3019e-02, test_loss 2.7025e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15600, train_loss 8.5524e-04, test_loss 3.1782e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15700, train_loss 1.1982e-03, test_loss 7.2700e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15800, train_loss 2.3714e-04, test_loss 6.4497e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 15900, train_loss 1.6736e-03, test_loss 4.1622e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16000, train_loss 1.2616e-02, test_loss 3.2728e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16100, train_loss 2.5176e-04, test_loss 4.3613e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16200, train_loss 1.6784e-03, test_loss 3.6636e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16300, train_loss 2.3652e-03, test_loss 3.2497e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16400, train_loss 2.2977e-03, test_loss 1.7904e+00\n",
      "accuracy tensor(0.4801)\n",
      "iter 16500, train_loss 1.4616e-03, test_loss 3.3769e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16600, train_loss 2.8517e-01, test_loss 2.6633e-01\n",
      "accuracy tensor(0.5240)\n",
      "iter 16700, train_loss 3.5749e-05, test_loss 3.4615e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16800, train_loss 3.9868e-05, test_loss 3.2394e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 16900, train_loss 2.0254e-03, test_loss 3.3498e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17000, train_loss 4.0828e-03, test_loss 3.5715e-01\n",
      "accuracy tensor(0.5451)\n",
      "iter 17100, train_loss 1.2407e-02, test_loss 5.1995e-01\n",
      "accuracy tensor(0.5132)\n",
      "iter 17200, train_loss 2.2658e-05, test_loss 3.9819e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17300, train_loss 8.5511e-02, test_loss 4.0045e-01\n",
      "accuracy tensor(0.5799)\n",
      "iter 17400, train_loss 5.8852e-06, test_loss 3.2761e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17500, train_loss 3.0998e-02, test_loss 2.9073e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17600, train_loss 4.7628e-03, test_loss 4.2179e-01\n",
      "accuracy tensor(0.5026)\n",
      "iter 17700, train_loss 1.1020e-05, test_loss 3.1748e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17800, train_loss 8.3959e-05, test_loss 3.7636e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 17900, train_loss 5.9725e-01, test_loss 2.7790e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 18000, train_loss 1.7499e-06, test_loss 3.6095e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 18100, train_loss 2.9174e-02, test_loss 4.9652e-01\n",
      "accuracy tensor(0.4211)\n",
      "iter 18200, train_loss 1.7424e-03, test_loss 5.8550e-01\n",
      "accuracy tensor(0.4936)\n",
      "iter 18300, train_loss 1.0442e-01, test_loss 1.2809e+00\n",
      "accuracy tensor(0.4043)\n",
      "iter 18400, train_loss 4.8931e-01, test_loss 2.5064e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 18500, train_loss 9.4445e-03, test_loss 4.5874e-01\n",
      "accuracy tensor(0.5886)\n",
      "iter 18600, train_loss 1.2949e-03, test_loss 3.4276e-01\n",
      "accuracy tensor(0.4613)\n",
      "iter 18700, train_loss 1.0352e-04, test_loss 3.6476e-01\n",
      "accuracy tensor(0.4594)\n",
      "iter 18800, train_loss 3.0607e-02, test_loss 3.0965e-01\n",
      "accuracy tensor(0.5952)\n",
      "iter 18900, train_loss 3.1939e-06, test_loss 4.5318e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19000, train_loss 2.8768e-05, test_loss 3.8060e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19100, train_loss 8.2593e-01, test_loss 3.7536e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19200, train_loss 5.6376e-03, test_loss 3.6551e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19300, train_loss 6.2709e-01, test_loss 2.8755e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19400, train_loss 8.7010e-04, test_loss 4.0161e-01\n",
      "accuracy tensor(0.5420)\n",
      "iter 19500, train_loss 1.3017e-02, test_loss 3.4507e-01\n",
      "accuracy tensor(0.4445)\n",
      "iter 19600, train_loss 5.4021e-02, test_loss 7.3171e-01\n",
      "accuracy tensor(0.5408)\n",
      "iter 19700, train_loss 1.2437e-01, test_loss 2.6751e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 19800, train_loss 6.1870e-01, test_loss 6.4712e-01\n",
      "accuracy tensor(0.5649)\n",
      "iter 19900, train_loss 1.1749e-02, test_loss 7.8130e-01\n",
      "accuracy tensor(0.5542)\n",
      "iter 20000, train_loss 3.3640e-01, test_loss 4.9088e-01\n",
      "accuracy tensor(0.4580)\n",
      "iter 20100, train_loss 1.5441e+00, test_loss 1.5314e+00\n",
      "accuracy tensor(0.4243)\n",
      "iter 20200, train_loss 1.2594e-01, test_loss 2.7070e-01\n",
      "accuracy tensor(0.5314)\n",
      "iter 20300, train_loss 2.6792e-02, test_loss 3.2040e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 20400, train_loss 4.0856e-01, test_loss 3.0447e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 20500, train_loss 3.9117e-03, test_loss 4.3811e-01\n",
      "accuracy tensor(0.5543)\n",
      "iter 20600, train_loss 1.3116e-03, test_loss 3.4832e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 20700, train_loss 7.1693e-02, test_loss 5.4540e-01\n",
      "accuracy tensor(0.4912)\n",
      "iter 20800, train_loss 4.6204e-01, test_loss 2.5286e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 20900, train_loss 4.8815e-01, test_loss 2.5904e-01\n",
      "accuracy tensor(0.6471)\n",
      "iter 21000, train_loss 1.0737e-01, test_loss 8.3435e-01\n",
      "accuracy tensor(0.5013)\n",
      "iter 21100, train_loss 7.6158e-03, test_loss 4.6797e-01\n",
      "accuracy tensor(0.6642)\n",
      "iter 21200, train_loss 1.9522e-02, test_loss 3.3310e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 21300, train_loss 1.0854e-01, test_loss 2.5694e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 21400, train_loss 8.4449e-01, test_loss 3.5595e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 21500, train_loss 1.6343e-01, test_loss 3.1576e-01\n",
      "accuracy tensor(0.6840)\n",
      "iter 21600, train_loss 5.3127e-02, test_loss 2.7791e-01\n",
      "accuracy tensor(0.6090)\n",
      "iter 21700, train_loss 9.5326e-04, test_loss 3.9392e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 21800, train_loss 4.5921e-02, test_loss 2.7495e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 21900, train_loss 4.1795e-03, test_loss 2.6063e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22000, train_loss 3.5889e-03, test_loss 7.3092e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22100, train_loss 2.8388e-03, test_loss 3.5096e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22200, train_loss 7.8776e-01, test_loss 3.0561e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22300, train_loss 3.3538e-01, test_loss 3.9622e-01\n",
      "accuracy tensor(0.6782)\n",
      "iter 22400, train_loss 3.4271e-01, test_loss 3.0000e-01\n",
      "accuracy tensor(0.6711)\n",
      "iter 22500, train_loss 9.2354e-05, test_loss 2.7846e-01\n",
      "accuracy tensor(0.7073)\n",
      "iter 22600, train_loss 8.4234e-03, test_loss 2.8328e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22700, train_loss 1.3621e-04, test_loss 2.8221e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22800, train_loss 8.3437e-01, test_loss 3.2810e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 22900, train_loss 7.9394e-03, test_loss 2.8641e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23000, train_loss 4.3897e-01, test_loss 3.1509e-01\n",
      "accuracy tensor(0.6524)\n",
      "iter 23100, train_loss 4.1717e-03, test_loss 2.9074e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23200, train_loss 5.9356e-05, test_loss 2.8274e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23300, train_loss 6.8938e-03, test_loss 2.7484e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23400, train_loss 5.9066e-01, test_loss 2.8505e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23500, train_loss 5.1381e-06, test_loss 3.2641e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23600, train_loss 2.6259e-02, test_loss 2.8391e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 23700, train_loss 2.7904e-03, test_loss 3.4685e-01\n",
      "accuracy tensor(0.5570)\n",
      "iter 23800, train_loss 2.1447e-01, test_loss 2.7430e-01\n",
      "accuracy tensor(0.4569)\n",
      "iter 23900, train_loss 5.1258e-01, test_loss 2.6899e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 24000, train_loss 3.7572e-01, test_loss 2.6507e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 24100, train_loss 3.2227e-03, test_loss 3.0080e-01\n",
      "accuracy tensor(0.7018)\n",
      "iter 24200, train_loss 2.2457e-04, test_loss 3.7035e-01\n",
      "accuracy tensor(0.7348)\n",
      "iter 24300, train_loss 1.6952e-01, test_loss 2.6104e-01\n",
      "accuracy tensor(0.6184)\n",
      "iter 24400, train_loss 1.7482e-05, test_loss 4.4577e-01\n",
      "accuracy tensor(0.6845)\n",
      "iter 24500, train_loss 1.1095e-03, test_loss 4.8044e-01\n",
      "accuracy tensor(0.7512)\n",
      "iter 24600, train_loss 4.8028e-01, test_loss 3.8312e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 24700, train_loss 8.3849e-02, test_loss 3.4686e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 24800, train_loss 8.3783e-01, test_loss 7.1895e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 24900, train_loss 4.2379e-01, test_loss 2.9869e-01\n",
      "accuracy tensor(0.5997)\n",
      "iter 25000, train_loss 1.1917e-01, test_loss 2.5646e-01\n",
      "accuracy tensor(0.5997)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m loss = loss_fcn(outputs, labels)\n\u001b[32m      9\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43moptim\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m optim.zero_grad()\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28miter\u001b[39m % print_every == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:517\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    512\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    513\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    514\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m out = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[38;5;28mself\u001b[39m._optimizer_step_code()\n\u001b[32m    520\u001b[39m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:82\u001b[39m, in \u001b[36m_use_grad_for_differentiable.<locals>._use_grad\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     80\u001b[39m     torch.set_grad_enabled(\u001b[38;5;28mself\u001b[39m.defaults[\u001b[33m\"\u001b[39m\u001b[33mdifferentiable\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     81\u001b[39m     torch._dynamo.graph_break()\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     ret = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     84\u001b[39m     torch._dynamo.graph_break()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\adam.py:247\u001b[39m, in \u001b[36mAdam.step\u001b[39m\u001b[34m(self, closure)\u001b[39m\n\u001b[32m    235\u001b[39m     beta1, beta2 = group[\u001b[33m\"\u001b[39m\u001b[33mbetas\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    237\u001b[39m     has_complex = \u001b[38;5;28mself\u001b[39m._init_group(\n\u001b[32m    238\u001b[39m         group,\n\u001b[32m    239\u001b[39m         params_with_grad,\n\u001b[32m   (...)\u001b[39m\u001b[32m    244\u001b[39m         state_steps,\n\u001b[32m    245\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m247\u001b[39m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mamsgrad\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmaximize\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mforeach\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcapturable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdifferentiable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfused\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_scale\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfound_inf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdecoupled_weight_decay\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\optimizer.py:150\u001b[39m, in \u001b[36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(*args, **kwargs)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\adam.py:953\u001b[39m, in \u001b[36madam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, decoupled_weight_decay, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    951\u001b[39m     func = _single_tensor_adam\n\u001b[32m--> \u001b[39m\u001b[32m953\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecoupled_weight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\audre\\anaconda3\\envs\\mouse\\Lib\\site-packages\\torch\\optim\\adam.py:537\u001b[39m, in \u001b[36m_single_tensor_adam\u001b[39m\u001b[34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable, decoupled_weight_decay)\u001b[39m\n\u001b[32m    534\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    535\u001b[39m         denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m     \u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    539\u001b[39m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch.is_complex(params[i]):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "for epoch in range(num_epochs):\n",
    "    for iter in range(train_x.shape[0]):\n",
    "        inputs = train_x[iter]\n",
    "        labels = train_y[iter]\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fcn(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        optim.zero_grad()\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            preds = model.forward(test_x)\n",
    "            test_loss = loss_fcn(test_y, preds)\n",
    "            acc = accuracy(preds, test_y)\n",
    "            # logging\n",
    "            print(\"iter {}, train_loss {:.4e}, test_loss {:.4e}\".format(iter, loss.item(), test_loss.item()))\n",
    "            print(\"accuracy\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5643d43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9522a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90cfdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340dd05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b710c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6d3070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['annotations', 'keypoints', 'metadata', 'scores'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['annotator-id_0']['task1/test/mouse071_task1_annotator1'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffe1ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints_test_train():\n",
    "    prefix = '.\\\\task1_MARS_features\\\\calms21_task1_features'\n",
    "    train_files = os.listdir(prefix + '\\\\train')\n",
    "    test_files = os.listdir(prefix + '\\\\test')\n",
    "    test, train = [], []\n",
    "    for file in train_files:\n",
    "        train.append(np.load(prefix + '\\\\train\\\\' + file))\n",
    "    for file in test_files:\n",
    "        test.append(np.load(prefix + '\\\\test\\\\' + file))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac61be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_keypoints, test_keypoints = load_keypoints_test_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ea035ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21364, 2, 2, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]['keypoints'].shape\n",
    "# 30 fps, ~10 minutes\n",
    "# 21364 frames\n",
    "# 2 mice, xy pos, 7 features\n",
    "# will probably look at ~5 seconds=150 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ac02d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
